# üéØ TODO: Sistema OSINT Completo - InfoPanama

**Fecha:** 12 de Diciembre, 2025
**Objetivo:** Montar sistema OSINT completamente funcional con los 10 crawlers operativos

---

## üî¥ PRIORIDAD CR√çTICA (Hacer AHORA)

### 1. ‚úÖ Verificar que los 10 Crawlers Funcionan
**Estado:** En proceso de verificaci√≥n
**Crawlers:**
- [ ] La Prensa
- [ ] TVN
- [ ] Telemetro
- [ ] Panama Am√©rica
- [ ] Cr√≠tica
- [ ] La Estrella
- [ ] Capital Financiero
- [ ] Metro Libre (nuevo)
- [ ] RPC Radio (nuevo)
- [ ] Gaceta Oficial

**Acci√≥n:**
```bash
cd packages/crawler
npm run crawl:all
# Verificar que cada crawler extrae art√≠culos
```

**Resultado esperado:**
- M√≠nimo 5-10 art√≠culos por crawler
- Sin errores fatales
- Claims extra√≠dos con IA

---

### 2. ‚ùå Probar Sistema de Verificaci√≥n con IA
**Estado:** NUNCA PROBADO
**Problema:** No sabemos si funciona end-to-end

**Acci√≥n:**
1. Ir a `http://localhost:3000/admin/dashboard/claims`
2. Seleccionar cualquier claim
3. Click en "Verificar con IA"
4. Verificar que:
   - Se genera veredicto
   - Se guarda en BD
   - Aparece en la p√°gina del claim

**Archivos involucrados:**
- `packages/convex/convex/verification.ts` - Action verifyClaim
- `apps/web/src/app/admin/dashboard/claims/[id]/review/page.tsx` - UI

**Si falla:** Revisar logs de Convex y consola del navegador

---

### 3. ‚ùå Publicar Claims al Homepage
**Estado:** 0 claims p√∫blicos
**Problema:** Landing page vac√≠a, usuarios no ven contenido

**Acci√≥n:**
1. Verificar 5-10 claims con IA
2. Revisar manualmente que veredictos sean correctos
3. En dashboard, cambiar:
   - `status` ‚Üí `"published"`
   - `isPublic` ‚Üí `true`
4. Verificar que aparecen en `http://localhost:3000`

**SQL de ejemplo (via dashboard):**
```typescript
// En la UI del claim, bot√≥n "Publicar"
await ctx.db.patch(claimId, {
  status: "published",
  isPublic: true,
  publishedAt: Date.now()
})
```

---

### 4. ‚ùå Verificar Grafos de Relaciones
**Estado:** Desconocido si funcionan

**Acci√≥n:**
1. Ir a `http://localhost:3000/verificaciones/[cualquier-id]`
2. Verificar que se muestra:
   - Grafo de entidades relacionadas
   - Conexiones entre actores
   - Fuentes citadas
3. Si no funciona, revisar:
   - `apps/web/src/components/graph/MediaGraph.tsx`
   - Queries de entidades en Convex

---

### 5. ‚ö†Ô∏è Limpiar Entidades Hu√©rfanas
**Estado:** 38 de 182 entidades sin conexi√≥n (20.9%)

**Acci√≥n:**
```bash
cd packages/crawler
# Opci√≥n A: Conectarlas autom√°ticamente
npm run crawl:orphans

# Opci√≥n B: Eliminarlas
# Crear script para borrar entidades sin claims asociados
```

---

## üü° PRIORIDAD ALTA (Esta Semana)

### 6. ‚ùå Automatizar Crawlers con GitHub Actions
**Estado:** Crawlers solo se ejecutan manualmente

**Acci√≥n:**
1. Crear `.github/workflows/crawler-schedule.yml`
2. Configurar cron: cada 6 horas
3. Guardar secrets:
   - `CONVEX_URL`
   - `OPENAI_API_KEY`
   - `BROWSERBASE_API_KEY` (opcional)

**Archivo:**
```yaml
name: Crawler Autom√°tico
on:
  schedule:
    - cron: '0 */6 * * *'  # Cada 6 horas
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - run: npm install
      - run: npm run crawl:all
        env:
          CONVEX_URL: ${{ secrets.CONVEX_URL }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
```

---

### 7. ‚ùå Implementar Sistema de Snapshots
**Estado:** No se guardan copias de p√°ginas originales
**Riesgo:** Si el medio borra el art√≠culo, se pierde evidencia

**Opciones:**

#### Opci√≥n A: Digital Ocean Spaces + Playwright Screenshots
**Costo:** ~$5/mes (250 GB)

**Acci√≥n:**
1. Crear bucket en Digital Ocean Spaces
2. Modificar crawlers para tomar screenshot:
```typescript
const screenshot = await page.screenshot({ fullPage: true })
await uploadToSpaces(screenshot, `${articleId}.png`)
```
3. Guardar URL en BD:
```typescript
await createArticle({
  ...
  snapshotUrl: `https://spaces.digitalocean.com/infopanama/${articleId}.png`
})
```

#### Opci√≥n B: Archive.org (gratis)
```typescript
const archiveUrl = `https://web.archive.org/save/${articleUrl}`
await fetch(archiveUrl)
```

---

### 8. ‚ùå Botones R√°pidos de Moderaci√≥n
**Estado:** Todo requiere edici√≥n manual

**Acci√≥n:**
Agregar botones en `apps/web/src/app/admin/dashboard/claims/page.tsx`:

```tsx
<div className="flex gap-2">
  <Button onClick={() => publishClaim(claim._id)}>
    ‚úÖ Publicar
  </Button>
  <Button onClick={() => rejectClaim(claim._id)}>
    ‚ùå Rechazar
  </Button>
  <Button onClick={() => verifyClaim(claim._id)}>
    ü§ñ Verificar con IA
  </Button>
</div>
```

**Mutations necesarias:**
```typescript
// packages/convex/convex/claims.ts
export const publish = mutation({
  args: { claimId: v.id("claims") },
  handler: async (ctx, { claimId }) => {
    await ctx.db.patch(claimId, {
      status: "published",
      isPublic: true,
      publishedAt: Date.now()
    })
  }
})

export const reject = mutation({
  args: { claimId: v.id("claims") },
  handler: async (ctx, { claimId }) => {
    await ctx.db.patch(claimId, {
      status: "rejected"
    })
  }
})
```

---

### 9. ‚ùå Dashboard de Estad√≠sticas
**Estado:** No hay vista general del sistema

**Acci√≥n:**
Mejorar `apps/web/src/app/admin/dashboard/page.tsx`:

```tsx
<div className="grid grid-cols-4 gap-4">
  <StatCard
    title="Claims Totales"
    value={stats.totalClaims}
    icon="üìä"
  />
  <StatCard
    title="Verificados Hoy"
    value={stats.verifiedToday}
    icon="‚úÖ"
  />
  <StatCard
    title="Pendientes"
    value={stats.pending}
    icon="‚è≥"
  />
  <StatCard
    title="Publicados"
    value={stats.published}
    icon="üåê"
  />
</div>

<RecentActivity claims={recentClaims} />
<CrawlerStatus crawlers={crawlerStats} />
```

---

## üü¢ PRIORIDAD MEDIA (Pr√≥ximas 2 Semanas)

### 10. ‚ö†Ô∏è Sistema de Actores/KYA (Know Your Actor)
**Estado:** Tabla `actors` vac√≠a

**Objetivo:** Perfilar actores recurrentes (pol√≠ticos, empresarios, trolls)

**Acci√≥n:**
1. Crear interfaz en `/admin/dashboard/actores`
2. Permitir:
   - Crear perfil de actor manualmente
   - Ver historial de claims del actor
   - Asignar score de credibilidad
   - Marcar como "troll", "bot", "pol√≠tico", etc.

**Schema:**
```typescript
actors: defineTable({
  name: v.string(),
  slug: v.string(),
  type: v.union(
    v.literal("politician"),
    v.literal("journalist"),
    v.literal("businessperson"),
    v.literal("troll"),
    v.literal("bot")
  ),
  credibilityScore: v.number(), // 0-100
  bio: v.optional(v.string()),
  photoUrl: v.optional(v.string()),
  socialMedia: v.optional(v.object({
    twitter: v.optional(v.string()),
    instagram: v.optional(v.string()),
    facebook: v.optional(v.string())
  }))
})
```

---

### 11. ‚ö†Ô∏è Detecci√≥n Autom√°tica de Responsables
**Estado:** Tabla `probableResponsibles` vac√≠a

**Objetivo:** IA que identifica qui√©n difunde desinformaci√≥n

**Acci√≥n:**
Usar GPT para analizar patrones:
```typescript
const analysis = await openai.chat.completions.create({
  model: "gpt-4",
  messages: [{
    role: "system",
    content: "Analiza estos 10 claims verificados como FALSO. ¬øHay un patr√≥n de actores responsables?"
  }, {
    role: "user",
    content: JSON.stringify(falseClaims)
  }]
})
```

---

### 12. ‚ö†Ô∏è B√∫squeda Sem√°ntica con Embeddings
**Estado:** Campo `hasEmbedding` siempre false

**Objetivo:** Buscar claims similares por significado, no solo palabras

**Acci√≥n:**
1. Generar embeddings con OpenAI:
```typescript
const embedding = await openai.embeddings.create({
  model: "text-embedding-3-small",
  input: claim.claimText
})
```
2. Guardar en Qdrant o Pinecone
3. Implementar b√∫squeda:
```typescript
const similar = await qdrant.search({
  collection: "claims",
  vector: queryEmbedding,
  limit: 10
})
```

---

### 13. ‚ùå Sistema de Suscripciones
**Estado:** Tabla `subscriptions` vac√≠a

**Objetivo:** Usuarios siguen temas o actores

**Acci√≥n:**
1. UI para suscribirse:
```tsx
<Button onClick={() => subscribe("topic", "pol√≠tica")}>
  üîî Seguir tema "Pol√≠tica"
</Button>
```
2. Email notifications con Resend:
```typescript
await resend.emails.send({
  to: user.email,
  subject: "Nueva verificaci√≥n: Pol√≠tica",
  html: `<p>Se public√≥: ${claim.title}</p>`
})
```

---

### 14. ‚ùå Comentarios de Usuarios
**Estado:** Tabla `comments` vac√≠a

**Objetivo:** Engagement p√∫blico y crowdsourcing

**Acci√≥n:**
Agregar secci√≥n de comentarios en `/verificaciones/[id]`:
```tsx
<CommentsSection claimId={claim._id} />
```

**Moderaci√≥n:**
- Auto-aprobar usuarios verificados
- Requiere aprobaci√≥n para nuevos usuarios
- Detecci√≥n de spam con Akismet

---

## üîµ PRIORIDAD BAJA (Mes 2-3)

### 15. ‚ö†Ô∏è An√°lisis de Sentimiento
**Estado:** Campo `sentiment` nunca poblado

**Acci√≥n:**
```typescript
import { pipeline } from '@xenova/transformers'
const classifier = await pipeline('sentiment-analysis')
const result = await classifier(claim.claimText)
// result: { label: 'POSITIVE', score: 0.95 }
```

---

### 16. ‚ö†Ô∏è Grafo de Relaciones Visualizado
**Estado:** Datos existen pero visualizaci√≥n limitada

**Acci√≥n:**
Mejorar con D3.js force-directed graph:
```tsx
import ForceGraph2D from 'react-force-graph-2d'

<ForceGraph2D
  graphData={{
    nodes: entities,
    links: relations
  }}
  nodeLabel="name"
  linkLabel="type"
/>
```

---

### 17. ‚ùå Audit Logs Inmutables
**Estado:** Tabla `auditLogs` vac√≠a

**Objetivo:** Trazabilidad para compliance

**Acci√≥n:**
Log cada acci√≥n administrativa:
```typescript
await ctx.db.insert("auditLogs", {
  userId: user._id,
  action: "publish_claim",
  resourceType: "claim",
  resourceId: claimId,
  timestamp: Date.now(),
  metadata: { oldStatus: "new", newStatus: "published" }
})
```

---

### 18. ‚ùå API P√∫blica
**Estado:** No existe

**Objetivo:** Desarrolladores externos pueden consultar verificaciones

**Acci√≥n:**
```typescript
// /api/v1/claims
GET /api/v1/claims?status=published&limit=20
GET /api/v1/claims/:id
GET /api/v1/actors/:slug
GET /api/v1/stats

// Autenticaci√≥n con API Key
Authorization: Bearer sk_live_xxx
```

---

## üìä M√âTRICAS DE √âXITO

### Semana 1 (Ahora)
- [ ] 10 crawlers funcionando
- [ ] 50+ claims verificados con IA
- [ ] 20+ claims publicados en homepage
- [ ] Sistema de verificaci√≥n probado end-to-end
- [ ] Grafos funcionando

### Semana 2
- [ ] 200+ claims totales
- [ ] 100+ claims publicados
- [ ] Crawler autom√°tico con GitHub Actions
- [ ] Snapshots funcionando
- [ ] Dashboard con estad√≠sticas

### Mes 1
- [ ] 500+ claims totales
- [ ] 50+ actores perfilados
- [ ] B√∫squeda sem√°ntica funcionando
- [ ] Sistema de suscripciones
- [ ] 1000+ usuarios √∫nicos

---

## üöÄ QUICK WINS (Impacto Alto, Esfuerzo Bajo)

### Ahora Mismo (30 min cada uno)
1. ‚úÖ Ejecutar `npm run crawl:all` y verificar
2. ‚úÖ Publicar 20 claims manualmente al homepage
3. ‚úÖ Agregar botones de moderaci√≥n r√°pida
4. ‚úÖ Crear dashboard de estad√≠sticas b√°sico

### Hoy (2-3 horas cada uno)
5. ‚úÖ Configurar GitHub Actions para crawlers
6. ‚úÖ Implementar snapshots con Archive.org (gratis)
7. ‚úÖ Probar sistema de verificaci√≥n end-to-end
8. ‚úÖ Limpiar entidades hu√©rfanas

### Esta Semana
9. ‚úÖ Sistema de actores b√°sico
10. ‚úÖ Embeddings + b√∫squeda sem√°ntica
11. ‚úÖ Comentarios de usuarios
12. ‚úÖ Suscripciones por email

---

## üéØ PLAN DE ACCI√ìN INMEDIATO

```bash
# 1. Verificar crawlers (15 min)
cd packages/crawler
npm run crawl:all

# 2. Iniciar web app (1 min)
cd apps/web
npm run dev

# 3. Probar verificaci√≥n con IA (10 min)
# ‚Üí Abrir http://localhost:3000/admin/dashboard/claims
# ‚Üí Seleccionar claim
# ‚Üí Click "Verificar con IA"
# ‚Üí Confirmar que funciona

# 4. Publicar primeros claims (20 min)
# ‚Üí Revisar veredictos
# ‚Üí Cambiar status a "published"
# ‚Üí Verificar en homepage

# 5. Commit y push (5 min)
git add .
git commit -m "feat: sistema OSINT completo con 10 crawlers funcionando"
git push
```

---

## ‚úÖ CHECKLIST DE DEPLOYMENT

- [ ] Crawlers probados localmente
- [ ] Verificaci√≥n con IA funcionando
- [ ] Claims publicados en homepage
- [ ] Grafos de entidades funcionando
- [ ] GitHub Actions configurado
- [ ] Secrets configurados en GitHub
- [ ] Convex en producci√≥n
- [ ] DNS configurado
- [ ] SSL/HTTPS funcionando
- [ ] Analytics agregado (Plausible/Umami)
- [ ] Monitoring con Sentry
- [ ] Backups autom√°ticos de BD

---

## üÜò SOPORTE

**Si algo falla:**
1. Revisar logs de Convex: https://dashboard.convex.dev
2. Revisar consola del navegador (F12)
3. Revisar logs de crawler en terminal
4. Contactar a Claude Code con el error exacto

**Documentaci√≥n:**
- Convex: https://docs.convex.dev
- Next.js: https://nextjs.org/docs
- Playwright: https://playwright.dev

---

**√öltima actualizaci√≥n:** 12 de Diciembre, 2025
**Progreso:** 30% completado (base t√©cnica lista, falta contenido y automatizaci√≥n)
