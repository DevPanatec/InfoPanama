# ğŸ” InfoPanama OSINT Crawler

Sistema de crawling automÃ¡tico GRATIS para extraer noticias y verificar claims.

## ğŸ¯ Â¿QuÃ© hace?

1. **Scrapea medios panameÃ±os** (La Prensa, Gaceta Oficial, etc.)
2. **Extrae claims con IA** (GPT-5 mini identifica afirmaciones verificables)
3. **Guarda en Convex** (para verificaciÃ³n automÃ¡tica)

## ğŸš€ InstalaciÃ³n

```bash
cd packages/crawler
npm install
npx playwright install chromium
```

## âš™ï¸ ConfiguraciÃ³n

Copia `.env.example` a `.env` y configura:

```bash
# OpenAI API (para extracciÃ³n de claims)
OPENAI_API_KEY=sk-proj-...

# Convex (para guardar datos)
CONVEX_URL=https://your-deployment.convex.cloud
```

## ğŸ® Uso

### OpciÃ³n 1: Ejecutar todo el pipeline
```bash
npm run crawl:all
```

Esto harÃ¡:
1. âœ… Crawl de La Prensa (20 artÃ­culos)
2. âœ… Crawl de Gaceta Oficial (10 publicaciones)
3. âœ… ExtracciÃ³n de claims con IA
4. âœ… Guardado en Convex

### OpciÃ³n 2: Crawlers individuales
```bash
# Solo La Prensa
npm run crawl:prensa

# Solo Gaceta Oficial
npm run crawl:gaceta
```

### OpciÃ³n 3: Test de extracciÃ³n de claims
```bash
npm run extract:claims
```

## ğŸ“Š Output Esperado

```
ğŸš€ Iniciando Pipeline OSINT de InfoPanama
============================================================

ğŸ“° FASE 1: CRAWLING DE NOTICIAS
============================================================
ğŸ” Crawling La Prensa...
ğŸ“° Scrapeando secciÃ³n: /politica
ğŸ”— Encontrados 15 artÃ­culos en /politica
âœ… Scraped: Presidente anuncia reforma fiscal...
...
âœ… Fase 1 completada: 25 artÃ­culos scrapeados

ğŸ¤– FASE 2: EXTRACCIÃ“N DE CLAIMS CON IA
============================================================
ğŸ” Extrayendo claims de: "Presidente anuncia reforma..."
âœ… ExtraÃ­dos 2 claims verificables
   1. [HIGH] "El presupuesto 2025 serÃ¡ de $30 mil millones"
   2. [MEDIUM] "La tasa de desempleo bajÃ³ al 8%"
...

ğŸ’¾ FASE 3: GUARDANDO EN BASE DE DATOS
============================================================
ğŸ“ Procesando "Presidente anuncia reforma fiscal..."
   âœ… Claim creado: j97kaz8...
   âœ… Claim creado: k28lbx9...
...

ğŸ‰ PIPELINE COMPLETADO
============================================================
ğŸ“° ArtÃ­culos scrapeados: 25
ğŸ” Claims extraÃ­dos: 12
â±ï¸  Tiempo total: 142.35s
============================================================
```

## ğŸ¤– AutomatizaciÃ³n con Cron Jobs

El sistema incluye cron jobs en Convex que ejecutan automÃ¡ticamente:

### 1. Crawl cada 6 horas
- Extrae noticias recientes
- Identifica claims verificables
- Los guarda en estado "new"

### 2. VerificaciÃ³n automÃ¡tica cada hora
- Verifica claims con riskLevel HIGH o CRITICAL
- Usa GPT-5 mini con prompts avanzados
- Genera veredictos automÃ¡ticos

### 3. Limpieza semanal
- Elimina claims rechazados de hace >90 dÃ­as
- Optimiza la base de datos

**ConfiguraciÃ³n:** Ver `packages/convex/convex/crons.ts`

## ğŸ“ Estructura

```
packages/crawler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawlers/
â”‚   â”‚   â”œâ”€â”€ la-prensa.ts       # Crawler de La Prensa
â”‚   â”‚   â””â”€â”€ gaceta-oficial.ts  # Crawler de Gaceta Oficial
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â””â”€â”€ claim-extractor.ts # ExtracciÃ³n IA de claims
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ index.ts            # TypeScript types
â”‚   â””â”€â”€ index.ts                # Pipeline principal
â”œâ”€â”€ .env
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ”§ CÃ³mo Agregar MÃ¡s Fuentes

### Ejemplo: TVN Noticias

```typescript
// src/crawlers/tvn.ts
import { chromium } from 'playwright'
import * as cheerio from 'cheerio'

export async function crawlTVN() {
  const browser = await chromium.launch({ headless: true })
  const page = await browser.newPage()

  await page.goto('https://www.tvn-2.com/noticias')

  // Tu lÃ³gica de scraping aquÃ­
  // ...

  await browser.close()
  return articles
}
```

Luego agrÃ©galo a `src/index.ts`:

```typescript
import { crawlTVN } from './crawlers/tvn.js'

// En main():
const tvnArticles = await crawlTVN()
articles = [...articles, ...tvnArticles]
```

## ğŸ¯ Fuentes Soportadas Actualmente

- âœ… La Prensa (www.prensa.com)
- âœ… Gaceta Oficial (gacetaoficial.gob.pa)
- â³ TVN Noticias (prÃ³ximamente)
- â³ Telemetro (prÃ³ximamente)
- â³ La Estrella (prÃ³ximamente)

## ğŸ’¡ Tips

1. **Rate Limiting**: El crawler espera 2 segundos entre requests para no saturar los sitios
2. **User Agent**: Usamos un user agent real para evitar bloqueos
3. **Headless**: Chromium corre en modo headless (sin UI)
4. **Selectores CSS**: Los selectores pueden cambiar si los medios actualizan su diseÃ±o
5. **Costos**: GPT-5 mini cuesta ~$0.25-$2 por 1M tokens (muy barato)

## ğŸ› Troubleshooting

### Error: "OPENAI_API_KEY no configurado"
- Verifica que `.env` existe y tiene tu API key
- La API key debe empezar con `sk-proj-...`

### Error: "CONVEX_URL no configurado"
- Copia la URL de tu deployment desde Convex dashboard
- Debe ser `https://xxx.convex.cloud`

### Error: "Chromium no instalado"
```bash
npx playwright install chromium
```

### Selectores CSS no funcionan
- Los medios cambian su diseÃ±o ocasionalmente
- Actualiza los selectores en el crawler respectivo
- Usa las herramientas de desarrollador del navegador para encontrar los nuevos selectores

## ğŸ“ˆ MÃ©tricas

Crawl tÃ­pico (todas las fuentes):
- â±ï¸ **DuraciÃ³n**: ~2-3 minutos
- ğŸ“° **ArtÃ­culos**: ~25-30
- ğŸ” **Claims extraÃ­dos**: ~10-15
- ğŸ’° **Costo OpenAI**: ~$0.01-0.05

## ğŸ” Seguridad

- âœ… No almacenamos contenido protegido por copyright completo
- âœ… Solo guardamos metadata y citas breves
- âœ… Respetamos robots.txt
- âœ… Rate limiting para no saturar servidores
- âœ… API keys nunca se commitean (estÃ¡n en .env)

## ğŸš€ PrÃ³ximos Pasos

1. **MÃ¡s fuentes**: TVN, Telemetro, La Estrella, medios internacionales
2. **Webhooks**: Notificaciones cuando se detectan claims HIGH/CRITICAL
3. **Docker**: Containerizar para deployment fÃ¡cil
4. **Railway/Render**: Hospedar crawler para ejecuciÃ³n automÃ¡tica
5. **Monitoring**: Dashboard para ver status de crawls

---

**ğŸ‰ Â¡Sistema OSINT 100% GRATIS implementado!**

Solo pagas OpenAI (~$5-10/mes para uso moderado).
