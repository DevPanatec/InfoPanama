/**
 * Pipeline OSINT Completo para InfoPanama
 *
 * 1. Crawlea noticias de medios paname√±os
 * 2. Extrae claims verificables con IA
 * 3. Guarda en Convex para verificaci√≥n
 */

import 'dotenv/config'
import { ConvexHttpClient } from 'convex/browser'
import { crawlLaPrensa } from './crawlers/la-prensa.js'
import { crawlGacetaOficial } from './crawlers/gaceta-oficial.js'
import { crawlTVN } from './crawlers/tvn.js'
import { crawlTelemetro } from './crawlers/telemetro.js'
import { crawlPanamaAmerica } from './crawlers/panama-america.js'
import { crawlFocoInstagram } from './crawlers/foco-instagram.js'
import { crawlCritica } from './crawlers/critica.js'
import { crawlLaEstrella } from './crawlers/la-estrella.js'
import { crawlCapitalFinanciero } from './crawlers/capital-financiero.js'
import { crawlMetroLibre } from './crawlers/metro-libre.js'
import { crawlRPCRadio } from './crawlers/rpc-radio.js'
import { extractClaimsFromArticles } from './processors/claim-extractor.js'
import { extractActorsFromClaims } from './processors/actor-extractor.js'
import type { ScrapedArticle } from './types/index.js'

const CONVEX_URL = process.env.CONVEX_URL || process.env.NEXT_PUBLIC_CONVEX_URL

if (!CONVEX_URL) {
  throw new Error('CONVEX_URL no est√° configurado en .env')
}

const client = new ConvexHttpClient(CONVEX_URL)

// Helper para llamar mutations/queries de Convex sin tipos generados
async function createClaim(data: any) {
  return await client.mutation('claims:create' as any, data)
}

async function createArticle(data: any) {
  return await client.mutation('articles:create' as any, data)
}

async function createSource(data: any) {
  return await client.mutation('sources:create' as any, data)
}

async function getSourceBySlug(slug: string) {
  return await client.query('sources:getBySlug' as any, { slug })
}

// Mapeo de nombres de fuentes a slugs
const SOURCE_CONFIG: Record<
  string,
  { slug: string; name: string; url: string; type: 'media' | 'official' }
> = {
  'La Prensa': {
    slug: 'la-prensa',
    name: 'La Prensa',
    url: 'https://www.prensa.com',
    type: 'media',
  },
  'Gaceta Oficial': {
    slug: 'gaceta-oficial',
    name: 'Gaceta Oficial de Panam√°',
    url: 'https://www.gacetaoficial.gob.pa',
    type: 'official',
  },
  'TVN': {
    slug: 'tvn',
    name: 'TVN',
    url: 'https://www.tvn-2.com',
    type: 'media',
  },
  'Telemetro': {
    slug: 'telemetro',
    name: 'Telemetro',
    url: 'https://www.telemetro.com',
    type: 'media',
  },
  'Panama Am√©rica': {
    slug: 'panama-america',
    name: 'Panama Am√©rica',
    url: 'https://www.panamaamerica.com.pa',
    type: 'media',
  },
  'Foco': {
    slug: 'foco',
    name: 'Foco',
    url: 'https://foco.com.pa',
    type: 'media',
  },
  'Cr√≠tica': {
    slug: 'critica',
    name: 'Cr√≠tica',
    url: 'https://www.critica.com.pa',
    type: 'media',
  },
  'La Estrella de Panam√°': {
    slug: 'la-estrella',
    name: 'La Estrella de Panam√°',
    url: 'https://www.laestrella.com.pa',
    type: 'media',
  },
  'El Capital Financiero': {
    slug: 'capital-financiero',
    name: 'El Capital Financiero',
    url: 'https://elcapitalfinanciero.com',
    type: 'media',
  },
  'Metro Libre': {
    slug: 'metro-libre',
    name: 'Metro Libre',
    url: 'https://www.metrolibre.com',
    type: 'media',
  },
  'RPC Radio': {
    slug: 'rpc-radio',
    name: 'RPC Radio',
    url: 'https://www.rpc.com.pa',
    type: 'media',
  },
}

/**
 * Obtener o crear una fuente en Convex
 */
async function getOrCreateSource(sourceName: string) {
  const config = SOURCE_CONFIG[sourceName]

  if (!config) {
    throw new Error(`Source configuration not found for: ${sourceName}`)
  }

  // Intentar obtener la fuente existente
  let source = await getSourceBySlug(config.slug)

  // Si no existe, crearla
  if (!source) {
    console.log(`   üìå Creando nueva fuente: ${config.name}`)
    const sourceId = await createSource({
      name: config.name,
      slug: config.slug,
      url: config.url,
      type: config.type,
      isTrusted: true, // Fuentes oficiales y medios principales son confiables
      credibilityScore: 80,
      scrapingEnabled: true,
      scrapingFrequency: '6h',
    })

    // Obtener la fuente reci√©n creada
    source = await getSourceBySlug(config.slug)
  }

  return source
}

/**
 * Generar hash simple del contenido para detectar duplicados
 */
function generateContentHash(content: string): string {
  // Simple hash basado en contenido y longitud
  let hash = 0
  for (let i = 0; i < content.length; i++) {
    const char = content.charCodeAt(i)
    hash = (hash << 5) - hash + char
    hash = hash & hash // Convert to 32bit integer
  }
  return `${Math.abs(hash)}-${content.length}`
}

/**
 * Filtrar art√≠culos para SOLO incluir investigaciones y fact-checks SUSTANCIOSOS
 * NO chismes ni noticias informativas ligeras
 */
function isInvestigativeOrFactCheck(article: ScrapedArticle): boolean {
  const title = article.title.toLowerCase()
  const content = article.content.toLowerCase()
  const fullText = `${title} ${content}`

  // PALABRAS CLAVE FUERTES (debe tener al menos una)
  const strongInvestigationKeywords = [
    // Fact-checking EXPL√çCITO
    'verificamos', 'verificaci√≥n', 'fact-check', 'fact check',
    'es falso que', 'es verdadero que', 'comprobamos',
    'desmentido', 'desmiente', 'fake news', 'desinformaci√≥n',

    // Investigaci√≥n SERIA
    'investigaci√≥n revela', 'fiscal√≠a investiga', 'mp investiga',
    'documentos revelan', 'evidencia muestra', 'pruebas indican',
    'contratos irregulares', 'licitaci√≥n irregular',

    // Corrupci√≥n CONFIRMADA
    'corrupci√≥n', 'corrupto', 'soborno', 'sobornos', 'coima',
    'peculado', 'malversaci√≥n', 'lavado de dinero', 'blanqueo',
    'desv√≠o de fondos', 'enriquecimiento il√≠cito',

    // Legal/Judicial SERIO
    'procesado por', 'imputado por', 'sentenciado por',
    'tribunal ordena', 'juez ordena detenci√≥n', 'audiencia de imputaci√≥n',
    'acusado de corrupci√≥n', 'denuncia penal',

    // Transparencia
    'auditor√≠a revela', 'contralor√≠a detecta', 'falta de transparencia',
  ]

  // CHISMES o noticias ligeras (descartar si SOLO tiene estas sin keywords fuertes)
  const lightContentIndicators = [
    // Anuncios simples
    'anunci√≥', 'anuncia', 'inaugur√≥', 'inaugura',
    'visitar√°', 'asisti√≥', 'particip√≥ en evento',
    'declaraciones', 'opin√≥', 'coment√≥',

    // Deportes/Entretenimiento
    'mundial', 'copa', 'partido', 'gol', 'campeonato',
    'transmitir√°', 'transmisi√≥n', 'canal',
    'artista', 'cantante', 'actor', 'concierto', 'estreno',
    'far√°ndula', 'celebridad',

    // Servicios/Clima
    'pron√≥stico', 'temperatura', 'clima', 'lluvia',
    'tr√°fico', 'avenida cerrada', 'construcci√≥n',
  ]

  // 1. Si tiene palabras FUERTES de investigaci√≥n ‚Üí INCLUIR
  const hasStrongKeywords = strongInvestigationKeywords.some(keyword => fullText.includes(keyword))
  if (hasStrongKeywords) {
    return true
  }

  // 2. Si NO tiene palabras fuertes pero es contenido ligero ‚Üí DESCARTAR
  const isLightContent = lightContentIndicators.some(keyword => fullText.includes(keyword))
  if (isLightContent) {
    return false
  }

  // 3. Verificar si el art√≠culo tiene profundidad (no es solo un anuncio corto)
  const hasSubstance = content.length > 500 // Al menos 500 caracteres de contenido

  // 4. Palabras MODERADAS (solo incluir si tiene sustancia)
  const moderateKeywords = [
    'denuncia', 'acusaci√≥n', 'controversia', 'pol√©mica',
    'irregularidad', 'sospecha', 'cuestionamiento',
    'demanda', 'querella', 'audiencia', 'tribunal',
  ]

  const hasModerateKeywords = moderateKeywords.some(keyword => fullText.includes(keyword))

  // Solo incluir si tiene palabras moderadas Y contenido sustancioso
  return hasModerateKeywords && hasSubstance
}

async function main() {
  console.log('üöÄ Iniciando Pipeline OSINT de InfoPanama\n')
  console.log('='.repeat(60))

  const startTime = Date.now()

  // FASE 1: CRAWLING
  console.log('\nüì∞ FASE 1: CRAWLING DE NOTICIAS')
  console.log('='.repeat(60))

  let articles: ScrapedArticle[] = []

  try {
    // Crawl La Prensa
    console.log('\nüîç Crawling La Prensa...')
    const prensaArticles = await crawlLaPrensa()
    articles = [...articles, ...prensaArticles]

    // Crawl TVN
    console.log('\nüì∫ Crawling TVN...')
    const tvnArticles = await crawlTVN()
    articles = [...articles, ...tvnArticles]

    // Crawl Telemetro
    console.log('\nüì∫ Crawling Telemetro...')
    const telemetroArticles = await crawlTelemetro()
    articles = [...articles, ...telemetroArticles]

    // Crawl Panama Am√©rica
    console.log('\nüì∞ Crawling Panama Am√©rica...')
    const panamaAmericaArticles = await crawlPanamaAmerica()
    articles = [...articles, ...panamaAmericaArticles]

    // Crawl Cr√≠tica
    console.log('\nüì∞ Crawling Cr√≠tica...')
    const criticaArticles = await crawlCritica()
    articles = [...articles, ...criticaArticles]

    // Crawl La Estrella de Panam√°
    console.log('\nüì∞ Crawling La Estrella de Panam√°...')
    const laEstrellaArticles = await crawlLaEstrella()
    articles = [...articles, ...laEstrellaArticles]

    // Crawl El Capital Financiero
    console.log('\nüì∞ Crawling El Capital Financiero...')
    const capitalArticles = await crawlCapitalFinanciero()
    articles = [...articles, ...capitalArticles]

    // Crawl Metro Libre
    console.log('\nüì∞ Crawling Metro Libre...')
    const metroLibreArticles = await crawlMetroLibre()
    articles = [...articles, ...metroLibreArticles]

    // Crawl RPC Radio
    console.log('\nüìª Crawling RPC Radio...')
    const rpcArticles = await crawlRPCRadio()
    articles = [...articles, ...rpcArticles]

    // Crawl Foco (sitio web) - DESACTIVADO: dominio foco.com.pa no existe
    // TODO: Verificar dominio correcto de Foco o eliminar si solo usan Instagram
    // console.log('\nüì∞ Crawling Foco (sitio web)...')
    // const focoArticles = await crawlFoco()
    // articles = [...articles, ...focoArticles]

    // Crawl Foco Instagram
    console.log('\nüì∏ Crawling Foco Instagram (@focopanama)...')
    try {
      const focoIGArticles = await crawlFocoInstagram()
      articles = [...articles, ...focoIGArticles]
    } catch (error) {
      console.error('‚ö†Ô∏è  Error crawling Instagram (puede requerir configuraci√≥n):', error)
      console.log('   Continuando sin posts de Instagram...')
    }

    // Crawl Gaceta Oficial (pero se filtrar√° despu√©s)
    console.log('\nüèõÔ∏è  Crawling Gaceta Oficial...')
    const gacetaArticles = await crawlGacetaOficial()
    articles = [...articles, ...gacetaArticles]

    console.log(`\n‚úÖ Fase 1 completada: ${articles.length} art√≠culos scrapeados`)
  } catch (error) {
    console.error('‚ùå Error en fase de crawling:', error)
    process.exit(1)
  }

  // FASE 2: EXTRACCI√ìN DE CLAIMS
  console.log('\n\nü§ñ FASE 2: EXTRACCI√ìN DE CLAIMS CON IA')
  console.log('='.repeat(60))

  // FILTRO 1: Excluir Gaceta Oficial
  const withoutGaceta = articles.filter((article) =>
    article.sourceName !== 'Gaceta Oficial de Panam√°' &&
    !article.url?.includes('gacetaoficial.gob.pa')
  )
  console.log(`üì∞ Filtro 1 - Excluyendo Gaceta Oficial: ${withoutGaceta.length} de ${articles.length} art√≠culos`)

  // FILTRO 2: SOLO art√≠culos de investigaci√≥n y fact-checking
  const newsArticles = withoutGaceta.filter(isInvestigativeOrFactCheck)
  console.log(`üîç Filtro 2 - SOLO investigaciones y fact-checks: ${newsArticles.length} de ${withoutGaceta.length} art√≠culos`)
  console.log(`   ‚úÖ Incluye: verificaciones, investigaciones, denuncias, corrupci√≥n, fraude`)
  console.log(`   ‚ùå Excluye: deportes, entretenimiento, noticias generales, tr√°fico, clima`)
  console.log(`   ‚ö†Ô∏è  Art√≠culos descartados: ${articles.length - newsArticles.length}`)

  let totalClaimsExtracted = 0
  let totalActorsCreated = 0

  try {
    const results = await extractClaimsFromArticles(newsArticles)

    // FASE 3: GUARDAR EN CONVEX
    console.log('\n\nüíæ FASE 3: GUARDANDO EN BASE DE DATOS')
    console.log('='.repeat(60))

    for (const { article, claims } of results) {
      console.log(`\nüìù Procesando "${article.title.substring(0, 50)}..."`)
      console.log(`   Fuente: ${article.sourceName}`)

      // Primero obtener o crear la fuente
      let articleId = null
      try {
        // Obtener o crear source
        const source = await getOrCreateSource(article.sourceName)

        if (!source || !source._id) {
          throw new Error(`No se pudo obtener sourceId para ${article.sourceName}`)
        }

        console.log(`   üìÑ Guardando art√≠culo en base de datos...`)

        // Generar hash del contenido
        const contentHash = generateContentHash(article.content)

        // Guardar art√≠culo
        articleId = await createArticle({
          title: article.title,
          url: article.url,
          content: article.content,
          htmlContent: article.content, // En el futuro podr√≠amos guardar HTML
          sourceId: source._id,
          author: article.author,
          publishedDate: new Date(article.publishedDate).getTime(),
          topics: article.category ? [article.category] : [],
          contentHash: contentHash,
          imageUrl: article.imageUrl, // ‚úÖ Agregar imagen del art√≠culo
        })

        console.log(`   ‚úÖ Art√≠culo guardado: ${articleId}`)
      } catch (error: any) {
        // Si el error es por duplicado, no es un problema
        if (error?.message?.includes('already exists')) {
          console.log(`   ‚ÑπÔ∏è Art√≠culo ya existe en la base de datos (duplicado)`)
        } else {
          console.error(`   ‚ùå Error guardando art√≠culo:`, error)
        }
      }

      if (claims.length === 0) {
        console.log(`   ‚ÑπÔ∏è No se extrajeron claims de este art√≠culo`)
        continue
      }

      // EXTRACCI√ìN AUTOM√ÅTICA DE ACTORES
      console.log(`   üë• Extrayendo actores de ${claims.length} claims...`)
      const actorMap = await extractActorsFromClaims(claims, article.title)

      const actorsCreatedInArticle = Array.from(actorMap.values()).filter(id => id !== null).length
      if (actorsCreatedInArticle > 0) {
        totalActorsCreated += actorsCreatedInArticle
      }

      // Guardar cada claim en Convex
      for (let i = 0; i < claims.length; i++) {
        const claim = claims[i]
        const actorId = actorMap.get(i)

        try {
          // Validar speaker (evitar "null" literal)
          const validSpeaker = claim.speaker && claim.speaker !== 'null' && claim.speaker.toLowerCase() !== 'null'
            ? claim.speaker
            : null

          // Crear t√≠tulo v√°lido
          const claimTitle = validSpeaker
            ? `${validSpeaker}: "${claim.text.substring(0, 80)}..."`
            : `"${claim.text.substring(0, 100)}..."`

          // Crear el claim en Convex con actorId si se encontr√≥/cre√≥ uno
          const claimData: any = {
            title: claimTitle,
            description: claim.context || claim.text,
            claimText: claim.text,
            category: claim.category || 'otros',
            tags: [article.sourceName, article.category || 'General'].filter(Boolean),
            riskLevel: claim.riskLevel || 'MEDIUM',
            sourceType: 'auto_extracted',
            sourceUrl: article.url,
            imageUrl: article.imageUrl, // ‚úÖ Agregar imagen del art√≠culo al claim
            isPublic: true,
            isFeatured: claim.riskLevel === 'HIGH' || claim.riskLevel === 'CRITICAL',
            autoPublished: true,
            status: 'new', // üîç Requiere revisi√≥n manual antes de publicar
          }

          // Agregar actorId si existe
          if (actorId) {
            claimData.actorId = actorId
          }

          const claimId = await createClaim(claimData)

          console.log(`   ‚úÖ Claim creado: ${claimId}${actorId ? ' (con actor asociado)' : ''}`)
          totalClaimsExtracted++
        } catch (error) {
          console.error(`   ‚ùå Error guardando claim:`, error)
        }
      }

      // Rate limiting
      await new Promise((resolve) => setTimeout(resolve, 500))
    }

    console.log(`\n‚úÖ Fase 3 completada: ${totalClaimsExtracted} claims guardados`)
  } catch (error) {
    console.error('‚ùå Error en fase de extracci√≥n/guardado:', error)
  }

  // RESUMEN FINAL
  const duration = ((Date.now() - startTime) / 1000).toFixed(2)

  console.log('\n\nüéâ PIPELINE COMPLETADO')
  console.log('='.repeat(60))
  console.log(`üì∞ Art√≠culos scrapeados: ${articles.length}`)
  console.log(`üîç Claims extra√≠dos: ${totalClaimsExtracted}`)
  console.log(`üë• Actores creados/actualizados: ${totalActorsCreated}`)
  console.log(`‚è±Ô∏è  Tiempo total: ${duration}s`)
  console.log('='.repeat(60))

  console.log('\nüí° Pr√≥ximos pasos:')
  console.log('1. Revisar los claims en http://localhost:3000/admin/dashboard/claims')
  console.log('2. Verificar actores creados en http://localhost:3000/admin/dashboard/actores')
  console.log('3. Aprobar claims para verificaci√≥n autom√°tica')
  console.log('4. Publicar verificaciones en el homepage')

  process.exit(0)
}

// Manejo de errores global
process.on('unhandledRejection', (error) => {
  console.error('‚ùå Error no manejado:', error)
  process.exit(1)
})

// Ejecutar
main().catch((error) => {
  console.error('‚ùå Error fatal:', error)
  process.exit(1)
})
