# ğŸ•·ï¸ Lista de Crawlers - InfoPanama

Todos los crawlers disponibles para extraer noticias de medios panameÃ±os.

---

## ğŸ“° Medios Activos (11 crawlers)

### 1. **La Prensa** ğŸ“°
- **URL**: https://www.prensa.com
- **Tipo**: PeriÃ³dico tradicional
- **Script**: `npm run crawl:prensa`
- **Estado**: âœ… Activo

### 2. **TVN** ğŸ“º
- **URL**: https://www.tvn-2.com
- **Tipo**: Canal de TV / Noticias
- **Script**: Incluido en `crawl:all`
- **Estado**: âœ… Activo

### 3. **Telemetro** ğŸ“º
- **URL**: https://www.telemetro.com
- **Tipo**: Canal de TV / Noticias
- **Script**: Incluido en `crawl:all`
- **Estado**: âœ… Activo

### 4. **Panama AmÃ©rica** ğŸ“°
- **URL**: https://www.panamaamerica.com.pa
- **Tipo**: PeriÃ³dico
- **Script**: Incluido en `crawl:all`
- **Estado**: âœ… Activo

### 5. **CrÃ­tica** ğŸ“°
- **URL**: https://www.critica.com.pa
- **Tipo**: PeriÃ³dico
- **Script**: Incluido en `crawl:all`
- **Estado**: âœ… Activo

### 6. **La Estrella de PanamÃ¡** ğŸ“°
- **URL**: https://www.laestrella.com.pa
- **Tipo**: PeriÃ³dico
- **Script**: Incluido en `crawl:all`
- **Estado**: âœ… Activo

### 7. **El Capital Financiero** ğŸ’°
- **URL**: https://elcapitalfinanciero.com
- **Tipo**: Medio econÃ³mico/financiero
- **Script**: `npm run crawl:capital`
- **Estado**: âœ… Activo
- **Secciones**: EconomÃ­a, Finanzas, Negocios, PolÃ­tica

### 8. **Metro Libre** ğŸ“° â­ NUEVO
- **URL**: https://www.metrolibre.com
- **Tipo**: PeriÃ³dico digital
- **Script**: `npm run crawl:metro`
- **Estado**: âœ… Activo
- **Agregado**: Diciembre 2025

### 9. **RPC Radio** ğŸ“» â­ NUEVO
- **URL**: https://www.rpc.com.pa
- **Tipo**: Radio / Noticias
- **Script**: `npm run crawl:rpc`
- **Estado**: âœ… Activo
- **Agregado**: Diciembre 2025

### 10. **Foco (Instagram)** ğŸ“¸
- **URL**: https://instagram.com/focopanama
- **Tipo**: Medio digital / Redes sociales
- **Script**: Incluido en `crawl:all`
- **Estado**: âœ… Activo
- **Requiere**: Browserbase configurado

### 11. **Gaceta Oficial** ğŸ›ï¸
- **URL**: https://www.gacetaoficial.gob.pa
- **Tipo**: PublicaciÃ³n oficial del gobierno
- **Script**: `npm run crawl:gaceta`
- **Estado**: âœ… Activo
- **Nota**: NO se extraen claims (documentos legales, no verificables)

---

## ğŸš« Crawlers Desactivados

### Foco (Sitio Web)
- **URL**: https://foco.com.pa
- **Estado**: âŒ Desactivado
- **RazÃ³n**: Dominio no disponible o cambiÃ³
- **Alternativa**: Usar crawler de Instagram (@focopanama)

---

## ğŸ“Š EstadÃ­sticas

| CategorÃ­a | Cantidad |
|-----------|----------|
| **Crawlers Activos** | 11 |
| **Medios Tradicionales** | 6 |
| **Canales TV** | 2 |
| **Radio** | 1 |
| **EconÃ³micos** | 1 |
| **Redes Sociales** | 1 |
| **Oficiales** | 1 |

---

## ğŸš€ CÃ³mo Usar

### Ejecutar todos los crawlers
```bash
cd packages/crawler
npm run crawl:all
```

### Ejecutar crawler individual
```bash
# La Prensa
npm run crawl:prensa

# Metro Libre
npm run crawl:metro

# RPC Radio
npm run crawl:rpc

# Capital Financiero
npm run crawl:capital

# Gaceta Oficial
npm run crawl:gaceta
```

---

## ğŸ”§ Agregar Nuevo Crawler

### 1. Crear archivo del crawler
```typescript
// packages/crawler/src/crawlers/nuevo-medio.ts
import { chromium } from 'playwright'
import type { ScrapedArticle } from '../types'

export async function crawlNuevoMedio(): Promise<ScrapedArticle[]> {
  // ... implementaciÃ³n
}
```

### 2. Agregar al index.ts
```typescript
// Importar
import { crawlNuevoMedio } from './crawlers/nuevo-medio.js'

// Agregar configuraciÃ³n de fuente
'Nuevo Medio': {
  slug: 'nuevo-medio',
  name: 'Nuevo Medio',
  url: 'https://nuevomedio.com',
  type: 'media',
},

// Agregar llamada en main()
console.log('\nğŸ“° Crawling Nuevo Medio...')
const nuevoMedioArticles = await crawlNuevoMedio()
articles = [...articles, ...nuevoMedioArticles]
```

### 3. Agregar script en package.json
```json
{
  "scripts": {
    "crawl:nuevo": "tsx src/crawlers/nuevo-medio.ts"
  }
}
```

### 4. Probar
```bash
npm run crawl:nuevo
```

---

## ğŸ“ Plantilla de Crawler

```typescript
/**
 * Crawler para [NOMBRE DEL MEDIO]
 * [DescripciÃ³n breve]
 */

import { chromium } from 'playwright'
import type { ScrapedArticle } from '../types'

const BASE_URL = 'https://ejemplo.com'

export async function crawlEjemplo(): Promise<ScrapedArticle[]> {
  console.log('ğŸ“° Iniciando crawler de Ejemplo...')

  const browser = await chromium.launch({ headless: true })
  const context = await browser.newContext({
    userAgent: 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...',
  })

  const page = await context.newPage()
  const articles: ScrapedArticle[] = []

  try {
    await page.goto(BASE_URL, {
      waitUntil: 'domcontentloaded',
      timeout: 30000,
    })

    // Extraer artÃ­culos...

    console.log(`âœ… Ejemplo: ${articles.length} artÃ­culos extraÃ­dos`)
  } catch (error) {
    console.error('âŒ Error en crawler de Ejemplo:', error)
  } finally {
    await browser.close()
  }

  return articles.filter(a => a.content && a.content.length > 100)
}

// Si se ejecuta directamente
if (import.meta.url === `file://${process.argv[1]}`) {
  crawlEjemplo()
    .then((articles) => {
      console.log(`\nğŸ“Š Total: ${articles.length} artÃ­culos`)
      articles.forEach((a, i) => {
        console.log(`${i + 1}. ${a.title}`)
      })
    })
    .catch(console.error)
}
```

---

## ğŸ¯ PrÃ³ximos Crawlers Sugeridos

- [ ] **Nex Noticias** (nexnoticias.com)
- [ ] **TVMax** (tvmax-9.com)
- [ ] **Mi Diario** (midiario.com)
- [ ] **Radio La Exitosa** (laexitosa.com.pa)
- [ ] **DÃ­a a DÃ­a** (dia-a-dia.com.pa)
- [ ] **El Siglo** (elsiglo.com.pa)

---

## ğŸ“š DocumentaciÃ³n TÃ©cnica

### Tipo ScrapedArticle
```typescript
interface ScrapedArticle {
  title: string
  url: string
  sourceUrl: string
  sourceName: string
  sourceType: 'news_website' | 'social_media' | 'official_document'
  content: string
  scrapedAt: string
  publishedDate: string
  imageUrl?: string
  author?: string
  category?: string
}
```

### Mejores PrÃ¡cticas

1. **Respetar rate limits**: Usar `page.waitForTimeout()` entre requests
2. **Manejo de errores**: Usar try/catch y continuar con siguiente artÃ­culo
3. **User agent**: Siempre configurar user agent realista
4. **Filtrar contenido**: Solo artÃ­culos con >100 caracteres
5. **Logs claros**: Usar emojis y mensajes descriptivos
6. **Timeout razonable**: 15-30 segundos por pÃ¡gina

---

**Ãšltima actualizaciÃ³n**: Diciembre 2025
