# ğŸ” ROADMAP: ImplementaciÃ³n OSINT Completa

## Estado Actual: âš ï¸ OSINT Pasivo (Solo Prompts)

Actualmente la IA **NO** tiene acceso a informaciÃ³n en tiempo real. Solo usa:
- âœ… Conocimiento entrenado (hasta enero 2025)
- âœ… Prompts que le indican CÃ“MO verificar
- âœ… MetodologÃ­a profesional de fact-checking

**LimitaciÃ³n crÃ­tica**: La IA no puede verificar claims sobre eventos recientes o datos actualizados.

---

## ğŸ¯ Fase 1: Web Search Integration (CRÃTICO)

### OpciÃ³n A: Perplexity API (Recomendado)
```typescript
// packages/convex/convex/lib/perplexity.ts
import { Perplexity } from '@perplexity-ai/sdk'

export async function searchWithPerplexity(query: string) {
  const perplexity = new Perplexity(process.env.PERPLEXITY_API_KEY)

  const response = await perplexity.chat.completions.create({
    model: 'sonar', // Modelo con bÃºsqueda web real-time
    messages: [{
      role: 'user',
      content: `Busca informaciÃ³n verificable sobre: ${query}.
                Prioriza fuentes oficiales panameÃ±as (.gob.pa, contralorÃ­a, INEC).`
    }],
    return_citations: true,
    search_domain_filter: ['gob.pa'], // Filtrar dominios oficiales
  })

  return {
    answer: response.choices[0].message.content,
    citations: response.citations,
  }
}
```

**Ventajas**:
- âœ… BÃºsqueda + LLM en una llamada
- âœ… Retorna citas con URLs verificables
- âœ… Modelo optimizado para fact-checking
- âœ… ~$5/1M tokens (econÃ³mico)

**IntegraciÃ³n**:
```typescript
// En verification.ts
const searchResults = await searchWithPerplexity(
  `Verificar: "${claim.claimText}" en fuentes oficiales de PanamÃ¡`
)

// Agregar resultados al prompt de GPT-5 mini
const enhancedPrompt = `
${userPrompt}

## RESULTADOS DE BÃšSQUEDA OSINT:
${searchResults.answer}

Fuentes consultadas:
${searchResults.citations.map(c => `- ${c.url}`).join('\n')}
`
```

### OpciÃ³n B: Tavily AI (Alternativa)
- API especializada en bÃºsqueda para agentes de IA
- Filtra contenido, extrae informaciÃ³n relevante
- ~$0.002 por bÃºsqueda

### OpciÃ³n C: Exa.ai (Mejor para bÃºsqueda semÃ¡ntica)
- BÃºsqueda neural, no solo keywords
- Ideal para encontrar artÃ­culos similares
- ~$1.50/1000 bÃºsquedas

---

## ğŸ¯ Fase 2: Crawlers de Fuentes Oficiales

### A. Crawler de Gaceta Oficial
```typescript
// packages/crawler/src/crawlers/gaceta-oficial.ts
import { chromium } from 'playwright'

export async function crawlGacetaOficial() {
  const browser = await chromium.launch()
  const page = await browser.newPage()

  await page.goto('https://www.gacetaoficial.gob.pa/')

  // Extraer Ãºltimas publicaciones
  const publications = await page.$$eval('.publication-item', items =>
    items.map(item => ({
      title: item.querySelector('h3')?.textContent,
      date: item.querySelector('.date')?.textContent,
      url: item.querySelector('a')?.href,
      pdf: item.querySelector('.pdf-link')?.href,
    }))
  )

  // Guardar en Convex
  for (const pub of publications) {
    await ctx.runMutation(api.articles.create, {
      title: pub.title,
      url: pub.url,
      sourceId: gacetaOficialSourceId,
      sourceType: 'official_source',
      publishedDate: parseDate(pub.date),
    })
  }

  await browser.close()
}
```

### B. Crawler de ContralorÃ­a General
```typescript
// Scraping de reportes financieros, auditorÃ­as, estadÃ­sticas
// URL: https://www.contraloria.gob.pa/
```

### C. Crawler de INEC
```typescript
// Datos estadÃ­sticos oficiales
// URL: https://www.inec.gob.pa/
```

### D. Crawler de Asamblea Nacional
```typescript
// Leyes, proyectos, votaciones
// URL: https://www.asamblea.gob.pa/
```

### E. Medios de ComunicaciÃ³n
```typescript
// La Prensa: https://www.prensa.com/
// TVN: https://www.tvn-2.com/
// Telemetro: https://www.telemetro.com/
```

**Arquitectura**:
```
packages/crawler/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ crawlers/
â”‚   â”‚   â”œâ”€â”€ gaceta-oficial.ts
â”‚   â”‚   â”œâ”€â”€ contraloria.ts
â”‚   â”‚   â”œâ”€â”€ inec.ts
â”‚   â”‚   â”œâ”€â”€ asamblea.ts
â”‚   â”‚   â””â”€â”€ media/
â”‚   â”‚       â”œâ”€â”€ la-prensa.ts
â”‚   â”‚       â”œâ”€â”€ tvn.ts
â”‚   â”‚       â””â”€â”€ telemetro.ts
â”‚   â”œâ”€â”€ schedulers/
â”‚   â”‚   â””â”€â”€ cron.ts           # ProgramaciÃ³n de crawls
â”‚   â”œâ”€â”€ processors/
â”‚   â”‚   â”œâ”€â”€ text-extractor.ts
â”‚   â”‚   â”œâ”€â”€ pdf-parser.ts
â”‚   â”‚   â””â”€â”€ claim-extractor.ts
â”‚   â””â”€â”€ storage/
â”‚       â””â”€â”€ snapshot.ts       # Guardar snapshots en DO Spaces
```

---

## ğŸ¯ Fase 3: Vector Database + RAG

### A. Setup Qdrant (Vector DB)
```typescript
// packages/convex/convex/lib/qdrant.ts
import { QdrantClient } from '@qdrant/js-client-rest'
import OpenAI from 'openai'

const qdrant = new QdrantClient({
  url: process.env.QDRANT_URL,
  apiKey: process.env.QDRANT_API_KEY,
})

export async function indexArticle(article: Article) {
  const openai = new OpenAI()

  // Generar embedding
  const embedding = await openai.embeddings.create({
    model: 'text-embedding-3-large',
    input: article.content,
  })

  // Guardar en Qdrant
  await qdrant.upsert('articles', {
    points: [{
      id: article._id,
      vector: embedding.data[0].embedding,
      payload: {
        title: article.title,
        url: article.url,
        sourceId: article.sourceId,
        publishedDate: article.publishedDate,
      }
    }]
  })
}

export async function searchSimilarArticles(claimText: string, limit = 5) {
  const openai = new OpenAI()

  // Embedding del claim
  const embedding = await openai.embeddings.create({
    model: 'text-embedding-3-large',
    input: claimText,
  })

  // BÃºsqueda semÃ¡ntica
  const results = await qdrant.search('articles', {
    vector: embedding.data[0].embedding,
    limit,
    with_payload: true,
  })

  return results
}
```

### B. RAG en VerificaciÃ³n
```typescript
// En verification.ts
export const verifyClaim = action({
  handler: async (ctx, args) => {
    // 1. BÃºsqueda semÃ¡ntica de artÃ­culos relacionados
    const similarArticles = await searchSimilarArticles(claim.claimText)

    // 2. BÃºsqueda web con Perplexity
    const webResults = await searchWithPerplexity(claim.claimText)

    // 3. Construir contexto enriquecido
    const contextPrompt = `
## CONTEXTO DE NUESTRA BASE DE DATOS:
${similarArticles.map(a => `
Fuente: ${a.payload.title}
URL: ${a.payload.url}
Fecha: ${a.payload.publishedDate}
Relevancia: ${(a.score * 100).toFixed(0)}%
`).join('\n')}

## RESULTADOS DE BÃšSQUEDA WEB:
${webResults.answer}
Fuentes: ${webResults.citations.map(c => c.url).join(', ')}
`

    // 4. Enviar a GPT-5 mini con OSINT completo
    const response = await openai.chat.completions.create({
      model: 'gpt-5-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt + contextPrompt }
      ],
      response_format: { type: 'json_object' },
    })

    // ...
  }
})
```

---

## ğŸ¯ Fase 4: Snapshot System (Evidencia Inmutable)

### A. Capturar Snapshots con Playwright
```typescript
// packages/crawler/src/storage/snapshot.ts
import { chromium } from 'playwright'
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3'

export async function createSnapshot(url: string) {
  const browser = await chromium.launch()
  const page = await browser.newPage()

  await page.goto(url, { waitUntil: 'networkidle' })

  // Capturar mÃºltiples formatos
  const [html, pdf, screenshot] = await Promise.all([
    page.content(),
    page.pdf({ format: 'A4' }),
    page.screenshot({ fullPage: true }),
  ])

  // Subir a Digital Ocean Spaces
  const s3 = new S3Client({
    endpoint: process.env.DO_SPACES_ENDPOINT,
    region: 'nyc3',
    credentials: {
      accessKeyId: process.env.DO_SPACES_KEY,
      secretAccessKey: process.env.DO_SPACES_SECRET,
    }
  })

  const timestamp = Date.now()
  const baseKey = `snapshots/${timestamp}`

  await Promise.all([
    s3.send(new PutObjectCommand({
      Bucket: 'infopanama-snapshots',
      Key: `${baseKey}.html`,
      Body: html,
      ContentType: 'text/html',
    })),
    s3.send(new PutObjectCommand({
      Bucket: 'infopanama-snapshots',
      Key: `${baseKey}.pdf`,
      Body: pdf,
      ContentType: 'application/pdf',
    })),
    s3.send(new PutObjectCommand({
      Bucket: 'infopanama-snapshots',
      Key: `${baseKey}.png`,
      Body: screenshot,
      ContentType: 'image/png',
    })),
  ])

  await browser.close()

  return {
    htmlPath: `${baseKey}.html`,
    pdfPath: `${baseKey}.pdf`,
    screenshotPath: `${baseKey}.png`,
    contentHash: hashContent(html),
  }
}
```

---

## ğŸ¯ Fase 5: Automated Claim Extraction (NLP)

### Extraer Claims AutomÃ¡ticamente de ArtÃ­culos
```typescript
// packages/convex/convex/nlp/claim-extraction.ts
export const extractClaims = action({
  handler: async (ctx, args) => {
    const article = await ctx.runQuery(api.articles.getById, { id: args.articleId })

    const openai = getOpenAIClient()

    const response = await openai.chat.completions.create({
      model: 'gpt-4o', // Modelo mÃ¡s potente para extracciÃ³n
      messages: [{
        role: 'system',
        content: `Eres un experto en extraer afirmaciones verificables de artÃ­culos de noticias.

        Extrae SOLO afirmaciones que sean:
        1. Verificables objetivamente (con datos, fuentes)
        2. Relevantes para el contexto panameÃ±o
        3. Potencialmente impactantes (no trivialidades)
        4. De polÃ­ticos, funcionarios o figuras pÃºblicas

        Formato JSON:
        {
          "claims": [
            {
              "text": "La afirmaciÃ³n exacta",
              "speaker": "QuiÃ©n lo dijo",
              "context": "Contexto relevante",
              "category": "polÃ­tica|economÃ­a|salud|seguridad|infraestructura",
              "riskLevel": "LOW|MEDIUM|HIGH|CRITICAL",
              "isVerifiable": boolean
            }
          ]
        }`
      }, {
        role: 'user',
        content: `ArtÃ­culo:\nTÃ­tulo: ${article.title}\n\n${article.content}`
      }],
      response_format: { type: 'json_object' },
    })

    const result = JSON.parse(response.choices[0].message.content)

    // Crear claims automÃ¡ticamente
    for (const claim of result.claims) {
      if (claim.isVerifiable) {
        await ctx.runMutation(api.claims.create, {
          title: `${claim.speaker}: "${claim.text.substring(0, 50)}..."`,
          description: claim.context,
          claimText: claim.text,
          category: claim.category,
          sourceType: 'auto_extracted',
          sourceUrl: article.url,
          sourceId: article._id,
          riskLevel: claim.riskLevel,
        })
      }
    }
  }
})
```

---

## ğŸ“Š Arquitectura Final: OSINT Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js)                        â”‚
â”‚  - Dashboard de verificaciones                               â”‚
â”‚  - Vista de claims con evidencia                             â”‚
â”‚  - Explorador de fuentes                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  BACKEND (Convex)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Verification System                                  â”‚  â”‚
â”‚  â”‚  - GPT-5 mini con prompts avanzados                  â”‚  â”‚
â”‚  â”‚  - Perplexity para web search                        â”‚  â”‚
â”‚  â”‚  - Qdrant para RAG                                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CRAWLER SYSTEM                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Gaceta      â”‚  â”‚  ContralorÃ­a â”‚  â”‚  Medios      â”‚     â”‚
â”‚  â”‚  Oficial     â”‚  â”‚  General     â”‚  â”‚  PanameÃ±os   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                              â”‚
â”‚  Schedule: Cron jobs cada 1-6 horas                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  DATA LAYER                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Convex DB   â”‚  â”‚  Qdrant      â”‚  â”‚  DO Spaces   â”‚     â”‚
â”‚  â”‚  (Metadata)  â”‚  â”‚  (Vectors)   â”‚  â”‚  (Snapshots) â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’° Costos Estimados (Mensual)

### Servicios Necesarios:
1. **Perplexity API**: ~$50-100/mes (segÃºn uso)
2. **Qdrant Cloud**: ~$25-50/mes (1M vectors)
3. **Digital Ocean Spaces**: ~$5-10/mes (250GB)
4. **OpenAI GPT-5 mini**: ~$100-200/mes (verificaciones)
5. **Playwright Cloud** (opcional): ~$50/mes

**Total estimado**: $230-410/mes para OSINT completo

---

## ğŸš€ Plan de ImplementaciÃ³n Recomendado

### Semana 1-2: Web Search (CRÃTICO)
```bash
npm install @perplexity-ai/sdk
```
- Integrar Perplexity API
- Modificar verification.ts para incluir bÃºsqueda web
- Probar con claims reales

### Semana 3-4: Crawlers BÃ¡sicos
- Implementar crawler de Gaceta Oficial
- Implementar crawler de La Prensa
- Setup cron jobs con Convex scheduled functions

### Semana 5-6: Vector Database
- Setup Qdrant Cloud
- Implementar indexaciÃ³n de artÃ­culos
- RAG en sistema de verificaciÃ³n

### Semana 7-8: Snapshots + Refinamiento
- Implementar sistema de snapshots
- Setup Digital Ocean Spaces
- Testing completo y ajustes

---

## Â¿Empezamos con la Fase 1 (Web Search)?

Es lo mÃ¡s impactante y rÃ¡pido de implementar. Con Perplexity la IA podrÃ¡:
- âœ… Buscar en internet en tiempo real
- âœ… Acceder a fuentes oficiales actualizadas
- âœ… Verificar claims con informaciÃ³n reciente
- âœ… Citar fuentes especÃ­ficas

**Â¿Quieres que implemente Perplexity ahora?**
